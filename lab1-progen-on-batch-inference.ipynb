{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1 (inference): Generate protein sequences at scale with Progen2 on AWS Batch\n",
    "\n",
    "This notebook will guide you through defining Progen2 prompts with parameters, submitting Batch jobs, monitoring job status, and finally \n",
    "viewing generated sequences.\n",
    "\n",
    "#### Prerequisites\n",
    "- IAM roles configured with appropriate permissions\n",
    "- Progen2 docker image pushed to ECR\n",
    "- Batch resources provisioned (Compute Environment, Job Queue, Job Definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "First, let's get our AWS account information and set up variables we'll use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "\n",
    "##########################################################\n",
    "\n",
    "# Get AWS account information\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Define S3 bucket and folder names\n",
    "S3_BUCKET = f'workshop-data-{account_id}'\n",
    "LAB1_FOLDER = 'lab1-progen'\n",
    "LAB2_FOLDER = 'lab2-amplify'\n",
    "LAB3_FOLDER = 'lab3-esmfold'\n",
    "\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"S3 Bucket: {S3_BUCKET}\")\n",
    "\n",
    "##########################################################\n",
    "\n",
    "# Define model \n",
    "model_version = 'progen2-small'\n",
    "model_id = f'hugohrban/{model_version}' \n",
    "\n",
    "# Create batch client\n",
    "batch_client = boto3.client('batch')\n",
    "\n",
    "# Define Batch job queue and job definition \n",
    "job_queue_name = 'progen2-batch-job-queue'\n",
    "job_definition_name = 'progen2-job-definition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define prompts with parameters to generate protein sequences\n",
    "\n",
    "The inference parameters file will be stored on S3, allowing batch jobs to access and use it for sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile data/$LAB1_FOLDER/inference-params.json\n",
    "\n",
    "{\n",
    "    \"inference-params\": [\n",
    "        {\"prompt_id\": \"prompt-001\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.001, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-002\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.7, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-003\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.001, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-004\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.7, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-005\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.001, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-006\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.7, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-007\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.001, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-008\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.7, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-009\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.001, \"top_p\":0.9, \"top_k\":50},\n",
    "\n",
    "        {\"prompt_id\": \"prompt-010\", \"prompt\": \"MEVVIVTGMSGAGK\", \n",
    "        \"max_length\":100, \"temperature\": 0.7, \"top_p\":0.9, \"top_k\":50}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp data/$LAB1_FOLDER/inference-params.json s3://$S3_BUCKET/$LAB1_FOLDER/inference-params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate protein sequences with inference parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Submit Batch jobs\n",
    "\n",
    "* ```batch_count``` defines how many jobs will be created\n",
    "* ```batch_size``` defines how many sequences will be generated by each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 1\n",
    "batch_size = 10\n",
    "\n",
    "jobs = []\n",
    "for batchNumber in range(batch_count):\n",
    "\n",
    "    # Generate unique job name\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    job_name = f'progen2-batch-job-{batchNumber}-{timestamp}'\n",
    "\n",
    "    # Submit the job\n",
    "    response = batch_client.submit_job(\n",
    "        jobName=job_name,\n",
    "        jobQueue=job_queue_name,\n",
    "        jobDefinition=job_definition_name,\n",
    "        parameters={\n",
    "            'hfModelId': model_id,\n",
    "            's3InputParamsPath': f's3://{S3_BUCKET}/{LAB1_FOLDER}/inference-params.json',\n",
    "            'batchId' : f'batch-10{batchNumber}',\n",
    "            'batchSize': f'{batch_size}',\n",
    "            'batchNumber': f'{batchNumber}',\n",
    "            's3OutputPath': f's3://{S3_BUCKET}/{LAB1_FOLDER}'\n",
    "        }\n",
    "    )\n",
    "    jobs.append(response)\n",
    "\n",
    "    job_id = response['jobId']\n",
    "    print(f\"Submitted job: {response['jobName']}\")\n",
    "    print(f\"   Job ID: {job_id}\")\n",
    "    print(f\"   Job ARN: {response['jobArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Monitor status of the submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_job_status(job_id):\n",
    "    \"\"\"Get detailed job status information\"\"\"\n",
    "    response = batch_client.describe_jobs(jobs=[job_id])\n",
    "    job = response['jobs'][0]\n",
    "    \n",
    "    print(f\"Job Name: {job['jobName']}\")\n",
    "    print(f\"Job ID: {job['jobId']}\")\n",
    "    print(f\"Status: {job['status']}\")\n",
    "    \n",
    "    if 'statusReason' in job:\n",
    "        print(f\"Status Reason: {job['statusReason']}\")\n",
    "    \n",
    "    if 'startedAt' in job:\n",
    "        started_at = datetime.datetime.fromtimestamp(job['startedAt'] / 1000)\n",
    "        print(f\"Started At: {started_at}\")\n",
    "    \n",
    "    if 'stoppedAt' in job:\n",
    "        stopped_at = datetime.datetime.fromtimestamp(job['stoppedAt'] / 1000)\n",
    "        print(f\"Stopped At: {stopped_at}\")\n",
    "    \n",
    "\n",
    "# Check jobs status\n",
    "for job in jobs:\n",
    "    print_job_status(job['jobId'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: View generated sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Download FASTA files with generated sequences from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://$S3_BUCKET/$LAB1_FOLDER ./data/$LAB1_FOLDER --recursive --exclude \"*\" --include \"*.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Read FASTA file(s) and print generated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "path = f\"data/{LAB1_FOLDER}\"\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".fasta\"):\n",
    "\n",
    "        file_path = os.path.join(path, file)    \n",
    "        for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "            print(f\"ID: {record.id}\")\n",
    "            print(f\"Description: {record.description}\")\n",
    "            print(f\"Sequence: {record.seq}\")\n",
    "            print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
